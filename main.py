import argparse

from datasets import load_dataset, load_from_disk
import torch

from quinny_sae_fxns.autoencoder import SparseAutoencoder
from quinny_sae_fxns.config import Config
from quinny_sae_fxns.get_embeddings import extract_activations_and_add_to_dataset, extract_activations_and_save_hdf5, add_hdf5_to_dataset
from quinny_sae_fxns.model import load_tokenizer_and_model
from quinny_sae_fxns.sae_train_eval import train_sae_on_activations
from quinny_sae_fxns.utils import get_device, print_hf_file_sizes, print_system_info

def parse_arguments():
    parser = argparse.ArgumentParser(description="Configure parameters for extracting embeddings.")

    parser.add_argument('--extract', action='store_true', help='Extract embeddings only')
    parser.add_argument('--train', action='store_true', help='Train SAE on embeddings')
    parser.add_argument('--embeddings_dir',type=str, help='Directory of saved embeddings (optional)')
    
    parser.add_argument('--device', type=str, default=None, help='Device to run on (e.g., mps, cpu, cuda)')
    parser.add_argument('--data_source', type=str, default="osunlp/SMolInstruct", help='Huggingface source for the task')
    parser.add_argument('--task', type=str, default="name_conversion-s2i", help='Task for the model')
    parser.add_argument('--split', type=str, default="test", help='Data split (e.g., train, test, validation)')
    parser.add_argument('--use_test_subset',type=bool, default=True, help='whether to use the subset of 200 data points, if test split is chosen')

    # Transformer model parameters
    parser.add_argument('--model_name', type=str, default="facebook/galactica-125m", help='Huggingface pretrained model name')
    parser.add_argument('--d_model', type=int, default=768, help='Dimension of the model') #TODO: automate this
    parser.add_argument('--max_context_length', type=int, default=128, help='Maximum context length for model input')
    parser.add_argument('--max_new_length', type=int, default=128, help="Maximum new length of sequences generated by model")
    parser.add_argument('--vocab_size', type=int, default=50000, help='Vocabulary size') #TODO: automate this
    parser.add_argument('--transformer_layer_num', type=int, default=7, help='transformer layer number for embedding extraction')

    # Autoencoder model training parameters
    parser.add_argument('--R', type=int, default=12, help='scaling factor of original embedding dimension')
    parser.add_argument('--a_batch_size', type=int, default=8, help='Batch size for training the autoencoder')
    parser.add_argument('--a_lr', type=float, default=1e-6, help='Learning rate for the autoencoder')
    parser.add_argument('--a_num_epochs', type=int, default=20, help='Number of epochs for autoencoder training')
    parser.add_argument('--lambda_reg', type=float, default=3e-3, help='Regularization parameter')
    parser.add_argument('--num_act_samples', type=int, default=50, help='Number of activation samples')

    return parser.parse_args()

def extract_embeddings(config):
    print(f'Loading model using device {config.device}. This may take a while for the first time...')
    tokenizer, model = load_tokenizer_and_model(config.model_name, device=config.device)
    print(f'Retrieving {config.task} {config.split} data from {config.data_source}...')
    print_hf_file_sizes(config.data_source, repo_type='dataset')
    if config.split != "test":
        config.use_test_subset=False
    dataset = load_dataset(
        config.data_source, 
        split=config.split, 
        trust_remote_code=True, 
        tasks=(config.task,), 
        use_test_subset=config.use_test_subset
    ) 
    print(f'Generating predictions & extracting embeddings...')
    #activation_data = extract_activations_and_add_to_dataset(dataset, model, tokenizer, config)
    hdf5_path = extract_activations_and_save_hdf5(dataset, model, tokenizer, config)
    activation_data = add_hdf5_to_dataset(dataset, hdf5_path, tokenizer)
    activation_data.save_to_disk(config.embeddings_dir)

    
    print(f"Embeddings saved to {config.embeddings_dir}")

def train_from_embeddings(config):
    autoencoder = SparseAutoencoder(config.d_features,config.d_model).to(config.device)
    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=config.a_lr)
    activation_dataset = load_from_disk(config.embeddings_dir)
    activations = activation_dataset['activations']
    losses, recon_losses, reg_losses = train_sae_on_activations(activations, autoencoder, optimizer, config)
    torch.save(
    {
        'model_state_dict': autoencoder.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'losses': losses,
        'recon_losses': recon_losses,
        'reg_losses' : reg_losses,
        'steps': len(losses),
    }, config.sae_model_path)
    print(f"Saved model to {config.sae_model_path}")



def main():
    args = parse_arguments()
    if args.device is None:
        device = get_device()
    print(f"Running on {device} device")
    config = Config(
        device=args.device,
        data_source=args.data_source,
        task=args.task,
        split=args.split,
        use_test_subset=args.use_test_subset,
        model_name=args.model_name,
        d_model=args.d_model,
        max_context_length=args.max_context_length,
        max_new_length=args.max_new_length,
        vocab_size=args.vocab_size,
        transformer_layer_num=args.transformer_layer_num,
        R=args.R,
        a_batch_size=args.a_batch_size,
        a_lr=args.a_lr,
        a_num_epochs=args.a_num_epochs,
        lambda_reg=args.lambda_reg,
        num_act_samples=args.num_act_samples,
    )
    if not args.extract and not args.train:
        print("Error: Please specify either --extract or --train. Use --help for usage information.")
        return

    print_system_info()
    if args.extract:
            print("Extract embeddings only.")
            extract_embeddings(config)
    elif args.train:
        if args.embeddings_dir:
            config.embeddings_dir = args.embeddings_dir
            print(f"Train SAE with saved embeddings from {config.embeddings_dir}.")
            train_from_embedding(config)
        else:
            print("No saved embeddings. Extract embeddings and then train SAE.")
            extract_embeddings(config)
            train_from_embeddings(config)
    print_system_info()
    

if __name__ == "__main__":
    main()
